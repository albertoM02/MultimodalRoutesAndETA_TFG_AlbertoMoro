{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Alberto Moro Carrera</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "\n",
    "df = pd.read_csv('TrainDataMaritimo.csv', usecols=['distance', 'Climate', 'Date', 'eta', 'eta/km*100'], sep=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primera aproximación, usando el eta y regresión lineal multiple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             distance  month  Cloudy  Foggy  Hurricane  Rain  Storm  Sunny\n",
      "979725   20876.292024      1       0      0          1     0      0      0\n",
      "363359    4793.302676      3       1      0          0     0      0      0\n",
      "1056847   8819.486049      7       0      0          1     0      0      0\n",
      "131416   16980.881062      7       0      0          0     0      0      1\n",
      "978075    4402.827283      3       0      0          1     0      0      0\n",
      "...               ...    ...     ...    ...        ...   ...    ...    ...\n",
      "110268    7459.154078      5       0      0          0     0      0      1\n",
      "259178    3674.954229      7       1      0          0     0      0      0\n",
      "131932   14262.874348      3       0      0          0     0      0      1\n",
      "671155    9867.609684      4       0      0          0     1      0      0\n",
      "121958   20172.597836      6       0      0          0     0      0      1\n",
      "\n",
      "[905267 rows x 8 columns]\n",
      "Regresión Lineal Multiple R2:  0.7797162834553372\n",
      "Regresión Lineal Multiple RMSE:  268.2526888150247\n",
      "Duracion 0.039888858795166016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "df = pd.read_csv('TrainDataMaritimo.csv', usecols=['distance', 'Climate', 'Date', 'eta', 'eta/km*100'], sep=\",\")\n",
    "\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month #Obtenemos los meses\n",
    "\n",
    "# Remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Dividimos los datos entre datos de test y datos de entrenamiento.\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identificamos las variables que afectarán al cálculo de la variable que se quiera calcular.\n",
    "X_train = train_data[['distance', 'Climate', 'month']]\n",
    "\n",
    "#Solo funciona con valores numéricos, por lo que se deben convertir los valores climatologicos a una columa por cada uno\n",
    "#Se identifica con un 1 la columna del clima que haya\n",
    "X_train = pd.get_dummies(X_train, columns=['Climate'],  prefix='', prefix_sep='') \n",
    "print(X_train)\n",
    "\n",
    "#Identificamos la variable que se quiere calcular\n",
    "y_train = train_data['eta']\n",
    "\n",
    "#Especificamos el algoritmo que se utilizará\n",
    "model = LinearRegression()\n",
    "\n",
    "#Le pasamos las variables al modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos predicciones con los datos de test\n",
    "X_test = test_data[['distance', 'Climate', 'month']]\n",
    "X_test = pd.get_dummies(X_test, columns=['Climate'],  prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_test = test_data['eta']\n",
    "\n",
    "#Predecimos\n",
    "start = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "#Comparamos los valores predichos con los reales para evaluar la eficiencia\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Regresión Lineal Multiple R2: \", r2)\n",
    "print(\"Regresión Lineal Multiple RMSE: \", rmse)\n",
    "print(\"Duracion\", end - start)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             distance  month  Cloudy  Foggy  Hurricane  Rain  Storm  Sunny\n",
      "979725   20876.292024      1       0      0          1     0      0      0\n",
      "363359    4793.302676      3       1      0          0     0      0      0\n",
      "1056847   8819.486049      7       0      0          1     0      0      0\n",
      "131416   16980.881062      7       0      0          0     0      0      1\n",
      "978075    4402.827283      3       0      0          1     0      0      0\n",
      "...               ...    ...     ...    ...        ...   ...    ...    ...\n",
      "110268    7459.154078      5       0      0          0     0      0      1\n",
      "259178    3674.954229      7       1      0          0     0      0      0\n",
      "131932   14262.874348      3       0      0          0     0      0      1\n",
      "671155    9867.609684      4       0      0          0     1      0      0\n",
      "121958   20172.597836      6       0      0          0     0      0      1\n",
      "\n",
      "[905267 rows x 8 columns]\n",
      "Red Neuronal R2:  0.7909230299053582\n",
      "Red Neuronal RMSE:  261.3400591740146\n",
      "Duracion 0.11706352233886719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import time\n",
    " \n",
    "\n",
    "df = pd.read_csv('TrainDataMaritimo.csv', usecols=['distance', 'Climate', 'Date', 'eta', 'eta/km*100'], sep=\",\")\n",
    "\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month #Obtenemos los meses\n",
    "\n",
    "# Remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Dividimos los datos entre datos de test y datos de entrenamiento.\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identificamos las variables que afectarán al cálculo de la variable que se quiera calcular.\n",
    "X_train = train_data[['distance', 'Climate', 'month']]\n",
    "\n",
    "#Solo funciona con valores numéricos, por lo que se deben convertir los valores climatologicos a una columa por cada uno\n",
    "#Se identifica con un 1 la columna del clima que haya\n",
    "X_train = pd.get_dummies(X_train, columns=['Climate'],  prefix='', prefix_sep='') \n",
    "print(X_train)\n",
    "\n",
    "#Identificamos la variable que se quiere calcular\n",
    "y_train = train_data['eta']\n",
    "\n",
    "#Especificamos el algoritmo que se utilizará\n",
    "model_net = MLPRegressor(hidden_layer_sizes=(10,), activation='relu', solver='adam', max_iter=1000)\n",
    "\n",
    "\n",
    "#Le pasamos las variables al modelo\n",
    "model_net.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos predicciones con los datos de test\n",
    "X_test = test_data[['distance', 'Climate', 'month']]\n",
    "X_test = pd.get_dummies(X_test, columns=['Climate'],  prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_test = test_data['eta']\n",
    "\n",
    "#Predecimos\n",
    "start = time.time()\n",
    "y_pred = model_net.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "#Comparamos los valores predichos con los reales para evaluar la eficiencia\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Red Neuronal R2: \", r2)\n",
    "print(\"Red Neuronal RMSE: \", rmse)\n",
    "print(\"Duracion\", end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos con XGboost para ver si funciona mejor que la regresión linel, pues la regresión lineal arroja valores negativos cuando los etas son bajos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\alberto.moro\\anaconda3\\lib\\site-packages (1.7.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scipy in c:\\users\\alberto.moro\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\alberto.moro\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "[10:15:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGBoost R2:  0.8896787562098761\n",
      "XGBoost RMSE:  189.83769890559887\n",
      "Duracion 0.21505999565124512\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "df = pd.read_csv('TrainDataMaritimo.csv', usecols=['distance', 'Climate', 'Date', 'eta', 'eta/km*100'], sep=\",\")\n",
    "\n",
    "# Create a new column 'month' with the month of each date\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month \n",
    "\n",
    "# Remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the data into training and test datasets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Select the variables that affect the calculation of the target variable\n",
    "X_train = train_data[['distance', 'Climate', 'month']]\n",
    "\n",
    "# Convert categorical variables to one-hot encoded format\n",
    "X_train = pd.get_dummies(X_train, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "# Select the target variable\n",
    "y_train = train_data['eta']\n",
    "\n",
    "# Specify the XGBoost algorithm with appropriate parameters\n",
    "xgb_modeleta = xgb.XGBRegressor(objective='reg:linear', random_state=1)\n",
    "# Train the model using the training dataset\n",
    "xgb_modeleta.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test dataset\n",
    "X_test = test_data[['distance', 'Climate', 'month']]\n",
    "X_test = pd.get_dummies(X_test, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "# Select the target variable\n",
    "y_test = test_data['eta']\n",
    "\n",
    "# Generate predictions\n",
    "start = time.time()\n",
    "y_pred = xgb_modeleta.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"XGBoost R2: \", r2)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"XGBoost RMSE: \", rmse)\n",
    "print(\"Duracion\", end - start)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbol de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión R2:  0.9494063665890444\n",
      "Arbol de decisión RMSE:  128.55850726261394\n",
      "Duracion 0.5687625408172607\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn import tree\n",
    "import time\n",
    " \n",
    "\n",
    "df = pd.read_csv('TrainDataMaritimo.csv', usecols=['distance', 'Climate', 'Date', 'eta', 'eta/km*100'], sep=\",\")\n",
    "\n",
    "# Create a new column 'month' with the month of each date\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month \n",
    "\n",
    "# Remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the data into training and test datasets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Select the variables that affect the calculation of the target variable\n",
    "X_train = train_data[['distance', 'Climate', 'month']]\n",
    "\n",
    "# Convert categorical variables to one-hot encoded format\n",
    "X_train = pd.get_dummies(X_train, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "# Select the target variable\n",
    "y_train = train_data['eta']\n",
    "\n",
    "# Specify the XGBoost algorithm with appropriate parameters\n",
    "arbol_model = tree.DecisionTreeRegressor()\n",
    "\n",
    "# Train the model using the training dataset\n",
    "arbol_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test dataset\n",
    "X_test = test_data[['distance', 'Climate', 'month']]\n",
    "X_test = pd.get_dummies(X_test, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "# Select the target variable\n",
    "y_test = test_data['eta']\n",
    "\n",
    "# Generate predictions\n",
    "start = time.time()\n",
    "y_pred = arbol_model.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Árbol de Decisión R2: \", r2)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Arbol de decisión RMSE: \", rmse)\n",
    "print(\"Duracion\", end - start)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigue sin ser demasiado preciso con valores pequeños, para ello, probamos a predecir el eta/km y a la hora de devolver el resultado multiplicarlo por km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\alberto.moro\\anaconda3\\lib\\site-packages (1.7.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\alberto.moro\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\alberto.moro\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "XGBoost eta/km R2:  0.6645308870480692\n",
      "XGBoost RMSE:  0.015004874723070086\n",
      "Duracion 0.1494297981262207\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt \n",
    "import time\n",
    "\n",
    "df = pd.read_csv('TrainDataMaritimo.csv', usecols=['distance', 'Climate', 'Date', 'eta', 'eta/km'], sep=\",\")\n",
    "\n",
    "# Obtiene el mes de cada fecha (Es lo que realmente afecta al eta)\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month \n",
    "\n",
    "#Eliminamos valores nulos del set si los hubiera\n",
    "df = df.dropna()\n",
    "\n",
    "#Dividimos el dataset en 2, uno para el entrenamiento y otro para predecir y contrastar las predicciones.\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "#Variables que afectan a la predicción del eta\n",
    "X_train = train_data[['distance', 'Climate', 'month']]\n",
    "\n",
    "#Convertimos las variables no numéricas por columnas numéricas para cada uno de los valores que estas puedan adoptar,\n",
    "#Pues el modelo solo funciona con valores numéricos. \n",
    "X_train = pd.get_dummies(X_train, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_train = train_data['eta/km']\n",
    "\n",
    "#ALgoritmo\n",
    "xgb_model_eta_km = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "#Entrenamos el modelo con los 2 subdataset\n",
    "xgb_model_eta_km.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos predicciones\n",
    "X_test = test_data[['distance', 'Climate', 'month']]\n",
    "X_test = pd.get_dummies(X_test, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_test = test_data['eta/km']\n",
    "\n",
    "#Predecimos\n",
    "start = time.time()\n",
    "y_pred = xgb_model_eta_km.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"XGBoost eta/km R2: \", r2)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"XGBoost RMSE: \", rmse)\n",
    "print(\"Duracion\", end - start)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos con Regresion Lineal Multiple también"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresion Lineal Multiple eta/km R2:  0.46818786407026347\n",
      "Regresion Lineal Multiple RMSE:  0.018892317059643154\n",
      "Duracion 0.026407480239868164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt \n",
    "import time\n",
    "\n",
    "df = pd.read_csv('TrainDataMaritimo.csv', usecols=['distance', 'Climate', 'Date', 'eta', 'eta/km'], sep=\",\")\n",
    "\n",
    "# Obtiene el mes de cada fecha (Es lo que realmente afecta al eta)\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month \n",
    "\n",
    "#Eliminamos valores nulos del set si los hubiera\n",
    "df = df.dropna()\n",
    "\n",
    "#Dividimos el dataset en 2, uno para el entrenamiento y otro para predecir y contrastar las predicciones.\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "#Variables que afectan a la predicción del eta\n",
    "X_train = train_data[['distance', 'Climate', 'month']]\n",
    "\n",
    "#Convertimos las variables no numéricas por columnas numéricas para cada uno de los valores que estas puedan adoptar,\n",
    "#Pues el modelo solo funciona con valores numéricos. \n",
    "X_train = pd.get_dummies(X_train, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_train = train_data['eta/km']\n",
    "\n",
    "#ALgoritmo\n",
    "model_eta_km = LinearRegression()\n",
    "\n",
    "#Entrenamos el modelo con los 2 subdataset\n",
    "model_eta_km.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos predicciones\n",
    "X_test = test_data[['distance', 'Climate', 'month']]\n",
    "X_test = pd.get_dummies(X_test, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_test = test_data['eta/km']\n",
    "\n",
    "#Predecimos\n",
    "start = time.time()\n",
    "y_pred = model_eta_km.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Regresion Lineal Multiple eta/km R2: \", r2)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Regresion Lineal Multiple RMSE: \", rmse)\n",
    "print(\"Duracion\", end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbol de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de decisión eta/km R2:  0.8476972667578159\n",
      "Arbol de decisión RMSE:  0.010110204781965093\n",
      "Duracion 0.8175709247589111\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt \n",
    "import time\n",
    "\n",
    "df = pd.read_csv('TrainDataMaritimo.csv', usecols=['distance', 'Climate', 'Date', 'eta', 'eta/km'], sep=\",\")\n",
    "\n",
    "# Obtiene el mes de cada fecha (Es lo que realmente afecta al eta)\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month \n",
    "\n",
    "#Eliminamos valores nulos del set si los hubiera\n",
    "df = df.dropna()\n",
    "\n",
    "#Dividimos el dataset en 2, uno para el entrenamiento y otro para predecir y contrastar las predicciones.\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "#Variables que afectan a la predicción del eta\n",
    "X_train = train_data[['distance', 'Climate', 'month']]\n",
    "\n",
    "#Convertimos las variables no numéricas por columnas numéricas para cada uno de los valores que estas puedan adoptar,\n",
    "#Pues el modelo solo funciona con valores numéricos. \n",
    "X_train = pd.get_dummies(X_train, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_train = train_data['eta/km']\n",
    "\n",
    "#ALgoritmo\n",
    "model_tree_eta_km = tree.DecisionTreeRegressor()\n",
    "\n",
    "#Entrenamos el modelo con los 2 subdataset\n",
    "model_tree_eta_km.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos predicciones\n",
    "X_test = test_data[['distance', 'Climate', 'month']]\n",
    "X_test = pd.get_dummies(X_test, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_test = test_data['eta/km']\n",
    "\n",
    "#Predecimos\n",
    "start = time.time()\n",
    "y_pred = model_tree_eta_km.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Árbol de decisión eta/km R2: \", r2)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Arbol de decisión RMSE: \", rmse)\n",
    "print(\"Duracion\", end - start)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red neuronal eta/km R2:  -14114.408597886846\n",
      "Red Neuronal RMSE:  3.0778881297901246\n",
      "Duracion 0.06283283233642578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt \n",
    "import time\n",
    "\n",
    "df = pd.read_csv('TrainDataMaritimo.csv', usecols=['distance', 'Climate', 'Date', 'eta', 'eta/km'], sep=\",\")\n",
    "\n",
    "# Obtiene el mes de cada fecha (Es lo que realmente afecta al eta)\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month \n",
    "\n",
    "#Eliminamos valores nulos del set si los hubiera\n",
    "df = df.dropna()\n",
    "\n",
    "#Dividimos el dataset en 2, uno para el entrenamiento y otro para predecir y contrastar las predicciones.\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "#Variables que afectan a la predicción del eta\n",
    "X_train = train_data[['distance', 'Climate', 'month']]\n",
    "\n",
    "#Convertimos las variables no numéricas por columnas numéricas para cada uno de los valores que estas puedan adoptar,\n",
    "#Pues el modelo solo funciona con valores numéricos. \n",
    "X_train = pd.get_dummies(X_train, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_train = train_data['eta/km']\n",
    "\n",
    "#ALgoritmo\n",
    "model_net_eta_km = MLPRegressor(hidden_layer_sizes=(10,), activation='relu', solver='adam', max_iter=1000)\n",
    "\n",
    "#Entrenamos el modelo con los 2 subdataset\n",
    "model_net_eta_km.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos predicciones\n",
    "X_test = test_data[['distance', 'Climate', 'month']]\n",
    "X_test = pd.get_dummies(X_test, columns=['Climate'], prefix='', prefix_sep='')\n",
    "\n",
    "#Variable a predecir\n",
    "y_test = test_data['eta/km']\n",
    "\n",
    "#Predecimos\n",
    "start = time.time()\n",
    "y_pred = model_net_eta_km.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Red neuronal eta/km R2: \", r2)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Red Neuronal RMSE: \", rmse)\n",
    "print(\"Duracion\", end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos un valor manualmente"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        distance        Date  month  Cloudy  Foggy  Hurricane  Rain  Storm  Sunny  Predicted eta\n",
      "0    7000.246935  1998-05-29      5       0      0          0     0      1      0     454.548196\n",
      "1   14000.246935  1998-05-29      5       0      0          0     0      1      0     902.678124\n",
      "2    7000.246935  1998-05-29      5       1      0          0     0      0      0     313.189528\n",
      "3   14000.246935  1998-05-29      5       1      0          0     0      0      0     624.972809\n",
      "4    7000.246935  1998-05-29      5       0      1          0     0      0      0     399.499908\n",
      "5   14000.246935  1998-05-29      5       0      1          0     0      0      0     795.940237\n",
      "6    7000.246935  1998-05-29      5       0      0          1     0      0      0     533.553072\n",
      "7   14000.246935  1998-05-29      5       0      0          1     0      0      0    1077.325034\n",
      "8    7000.246935  1998-05-29      5       0      0          0     1      0      0     355.364043\n",
      "9   14000.246935  1998-05-29      5       0      0          0     1      0      0     708.712799\n",
      "10   7000.246935  1998-05-29      5       0      0          0     0      0      1     255.643441\n",
      "11  14000.246935  2005-05-29      5       0      0          0     0      0      1     512.526142\n",
      "12  14000.246935  2005-09-29      9       0      0          0     0      0      1     554.112857\n",
      "13  14000.246935  2005-12-29     12       0      0          0     0      0      1     689.607229\n",
      "14  14000.246935  2005-01-29      1       0      0          0     0      0      1     773.314153\n",
      "15  14000.246935  2005-04-29      4       0      0          0     0      0      1     512.810178\n",
      "16     90.311833  2023-04-26      4       0      0          0     0      0      1       2.994157\n",
      "17     90.311833  2005-04-26      4       0      0          0     0      0      1       2.994157\n",
      "18     90.311833  2005-04-26      4       0      0          0     1      0      0       3.890890\n",
      "19     20.311833  2005-04-26      4       0      0          0     0      0      1       0.673409\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "df = pd.read_csv('trainer1.csv', usecols=['distance', 'Climate', 'Date'], sep=\",\")\n",
    "\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month #Obtenemos los meses\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Climate'],  prefix='', prefix_sep='')\n",
    "\n",
    "# Use the trained model to make predictions on the entire dataset\n",
    "df['Predicted eta'] = xgb_model_eta_km.predict(df[['distance', 'month', 'Cloudy', 'Foggy', 'Hurricane', 'Rain', 'Storm', 'Sunny']])\n",
    "\n",
    "df['Predicted eta'] = df['Predicted eta'] * df['distance'] #Solo cambia esto\n",
    "\n",
    "# Print the entire dataframe with predicted eta column\n",
    "print(df.to_string())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor para calculo de eta directamente con linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        distance        Date  month  Cloudy  Foggy  Hurricane  Rain  Storm  Sunny  Predicted eta\n",
      "0    7000.246935  1998-05-29      5       0      0          0     0      1      0     620.942194\n",
      "1   14000.246935  1998-05-29      5       0      0          0     0      1      0    1103.621306\n",
      "2    7000.246935  1998-05-29      5       1      0          0     0      0      0     345.025122\n",
      "3   14000.246935  1998-05-29      5       1      0          0     0      0      0     827.704234\n",
      "4    7000.246935  1998-05-29      5       0      1          0     0      0      0     508.583727\n",
      "5   14000.246935  1998-05-29      5       0      1          0     0      0      0     991.262838\n",
      "6    7000.246935  1998-05-29      5       0      0          1     0      0      0     784.146247\n",
      "7   14000.246935  1998-05-29      5       0      0          1     0      0      0    1266.825358\n",
      "8    7000.246935  1998-05-29      5       0      0          0     1      0      0     426.599862\n",
      "9   14000.246935  1998-05-29      5       0      0          0     1      0      0     909.278974\n",
      "10   7000.246935  1998-05-29      5       0      0          0     0      0      1     233.579973\n",
      "11  14000.246935  2005-05-29      5       0      0          0     0      0      1     716.259085\n",
      "12  14000.246935  2005-09-29      9       0      0          0     0      0      1     632.547067\n",
      "13  14000.246935  2005-12-29     12       0      0          0     0      0      1     569.763054\n",
      "14  14000.246935  2005-01-29      1       0      0          0     0      0      1     799.971102\n",
      "15  14000.246935  2005-04-29      4       0      0          0     0      0      1     737.187089\n",
      "16     90.311833  2023-04-26      4       0      0          0     0      0      1    -221.960784\n",
      "17     90.311833  2005-04-26      4       0      0          0     0      0      1    -221.960784\n",
      "18     90.311833  2005-04-26      4       0      0          0     1      0      0     -28.940895\n",
      "19     20.311833  2005-04-26      4       0      0          0     0      0      1    -226.787575\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "df = pd.read_csv('trainer1.csv', usecols=['distance', 'Climate', 'Date'], sep=\",\")\n",
    "\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month #Obtenemos los meses\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Climate'],  prefix='', prefix_sep='')\n",
    "\n",
    "# Use the trained model to make predictions on the entire dataset\n",
    "df['Predicted eta'] = model.predict(df[['distance', 'month', 'Cloudy', 'Foggy', 'Hurricane', 'Rain', 'Storm', 'Sunny']])\n",
    "\n",
    "# Print the entire dataframe with predicted eta column\n",
    "print(df.to_string())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor para calculo de eta directamente con arboles de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        distance        Date  month  Cloudy  Foggy  Hurricane  Rain  Storm  Sunny  Predicted eta\n",
      "0    7000.246935  1998-05-29      5       0      0          0     0      1      0     451.203548\n",
      "1   14000.246935  1998-05-29      5       0      0          0     0      1      0     826.211762\n",
      "2    7000.246935  1998-05-29      5       1      0          0     0      0      0     448.583524\n",
      "3   14000.246935  1998-05-29      5       1      0          0     0      0      0     457.638693\n",
      "4    7000.246935  1998-05-29      5       0      1          0     0      0      0     386.386701\n",
      "5   14000.246935  1998-05-29      5       0      1          0     0      0      0     762.016091\n",
      "6    7000.246935  1998-05-29      5       0      0          1     0      0      0     386.330333\n",
      "7   14000.246935  1998-05-29      5       0      0          1     0      0      0    1020.432996\n",
      "8    7000.246935  1998-05-29      5       0      0          0     1      0      0     365.639794\n",
      "9   14000.246935  1998-05-29      5       0      0          0     1      0      0     679.895976\n",
      "10   7000.246935  1998-05-29      5       0      0          0     0      0      1     283.278173\n",
      "11  14000.246935  2005-05-29      5       0      0          0     0      0      1     576.396647\n",
      "12  14000.246935  2005-09-29      9       0      0          0     0      0      1     445.122802\n",
      "13  14000.246935  2005-12-29     12       0      0          0     0      0      1     762.513737\n",
      "14  14000.246935  2005-01-29      1       0      0          0     0      0      1     837.817019\n",
      "15  14000.246935  2005-04-29      4       0      0          0     0      0      1     576.396647\n",
      "16     90.311833  2023-04-26      4       0      0          0     0      0      1       6.407516\n",
      "17     90.311833  2005-04-26      4       0      0          0     0      0      1       6.407516\n",
      "18     90.311833  2005-04-26      4       0      0          0     1      0      0       7.151505\n",
      "19     20.311833  2005-04-26      4       0      0          0     0      0      1       6.407516\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "df = pd.read_csv('trainer1.csv', usecols=['distance', 'Climate', 'Date'], sep=\",\")\n",
    "\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month #Obtenemos los meses\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Climate'],  prefix='', prefix_sep='')\n",
    "\n",
    "# Use the trained model to make predictions on the entire dataset\n",
    "df['Predicted eta'] = arbol_model.predict(df[['distance', 'month', 'Cloudy', 'Foggy', 'Hurricane', 'Rain', 'Storm', 'Sunny']])\n",
    "\n",
    "# Print the entire dataframe with predicted eta column\n",
    "print(df.to_string())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor para calculo de eta directamente con xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        distance        Date  month  Cloudy  Foggy  Hurricane  Rain  Storm  Sunny  Predicted eta\n",
      "0    7000.246935  1998-05-29      5       0      0          0     0      1      0     441.919342\n",
      "1   14000.246935  1998-05-29      5       0      0          0     0      1      0     904.274475\n",
      "2    7000.246935  1998-05-29      5       1      0          0     0      0      0     311.630554\n",
      "3   14000.246935  1998-05-29      5       1      0          0     0      0      0     640.888733\n",
      "4    7000.246935  1998-05-29      5       0      1          0     0      0      0     404.192841\n",
      "5   14000.246935  1998-05-29      5       0      1          0     0      0      0     784.635315\n",
      "6    7000.246935  1998-05-29      5       0      0          1     0      0      0     535.914978\n",
      "7   14000.246935  1998-05-29      5       0      0          1     0      0      0    1080.744629\n",
      "8    7000.246935  1998-05-29      5       0      0          0     1      0      0     358.103729\n",
      "9   14000.246935  1998-05-29      5       0      0          0     1      0      0     716.289368\n",
      "10   7000.246935  1998-05-29      5       0      0          0     0      0      1     252.488205\n",
      "11  14000.246935  2005-05-29      5       0      0          0     0      0      1     516.639893\n",
      "12  14000.246935  2005-09-29      9       0      0          0     0      0      1     553.732300\n",
      "13  14000.246935  2005-12-29     12       0      0          0     0      0      1     739.718140\n",
      "14  14000.246935  2005-01-29      1       0      0          0     0      0      1     788.169067\n",
      "15  14000.246935  2005-04-29      4       0      0          0     0      0      1     517.053528\n",
      "16     90.311833  2023-04-26      4       0      0          0     0      0      1       3.302933\n",
      "17     90.311833  2005-04-26      4       0      0          0     0      0      1       3.302933\n",
      "18     90.311833  2005-04-26      4       0      0          0     1      0      0      10.692027\n",
      "19     20.311833  2005-04-26      4       0      0          0     0      0      1       3.302933\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "df = pd.read_csv('trainer1.csv', usecols=['distance', 'Climate', 'Date'], sep=\",\")\n",
    "\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month #Obtenemos los meses\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Climate'],  prefix='', prefix_sep='')\n",
    "\n",
    "# Use the trained model to make predictions on the entire dataset\n",
    "df['Predicted eta'] = xgb_modeleta.predict(df[['distance', 'month', 'Cloudy', 'Foggy', 'Hurricane', 'Rain', 'Storm', 'Sunny']])\n",
    "\n",
    "# Print the entire dataframe with predicted eta column\n",
    "print(df.to_string())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red Neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        distance        Date  month  Cloudy  Foggy  Hurricane  Rain  Storm  Sunny  Predicted eta\n",
      "0    7000.246935  1998-05-29      5       0      0          0     0      1      0     597.734805\n",
      "1   14000.246935  1998-05-29      5       0      0          0     0      1      0    1112.831629\n",
      "2    7000.246935  1998-05-29      5       1      0          0     0      0      0     271.577402\n",
      "3   14000.246935  1998-05-29      5       1      0          0     0      0      0     786.674226\n",
      "4    7000.246935  1998-05-29      5       0      1          0     0      0      0     479.051107\n",
      "5   14000.246935  1998-05-29      5       0      1          0     0      0      0     994.147931\n",
      "6    7000.246935  1998-05-29      5       0      0          1     0      0      0     761.238321\n",
      "7   14000.246935  1998-05-29      5       0      0          1     0      0      0    1276.335145\n",
      "8    7000.246935  1998-05-29      5       0      0          0     1      0      0     382.507333\n",
      "9   14000.246935  1998-05-29      5       0      0          0     1      0      0     897.604157\n",
      "10   7000.246935  1998-05-29      5       0      0          0     0      0      1     185.267196\n",
      "11  14000.246935  2005-05-29      5       0      0          0     0      0      1     598.654293\n",
      "12  14000.246935  2005-09-29      9       0      0          0     0      0      1     487.789049\n",
      "13  14000.246935  2005-12-29     12       0      0          0     0      0      1     404.640117\n",
      "14  14000.246935  2005-01-29      1       0      0          0     0      0      1     709.519536\n",
      "15  14000.246935  2005-04-29      4       0      0          0     0      0      1     626.370604\n",
      "16     90.311833  2023-04-26      4       0      0          0     0      0      1     185.267196\n",
      "17     90.311833  2005-04-26      4       0      0          0     0      0      1     185.267196\n",
      "18     90.311833  2005-04-26      4       0      0          0     1      0      0     185.267196\n",
      "19     20.311833  2005-04-26      4       0      0          0     0      0      1     185.267196\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('trainer1.csv', usecols=['distance', 'Climate', 'Date'], sep=\",\")\n",
    "\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month #Obtenemos los meses\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Climate'],  prefix='', prefix_sep='')\n",
    "\n",
    "# Use the trained model to make predictions on the entire dataset\n",
    "df['Predicted eta'] = model_net.predict(df[['distance', 'month', 'Cloudy', 'Foggy', 'Hurricane', 'Rain', 'Storm', 'Sunny']])\n",
    "\n",
    "# Print the entire dataframe with predicted eta column\n",
    "print(df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
